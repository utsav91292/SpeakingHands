## Project Description
Sign language translation is a promising application for vision-based gesture recognition methods, in which highly structured combinations of static and dynamic gestures correlate to a given lexicon. Machine learning techniques can be used to create interactive educational tools or to help a hearing-impaired person communicate more effectively with someone who does not know sign language.
## Implementation
This project represents the concept of American Sign Language recognition using Leap Motion Controller. Using this device, hearing impaired person can easily communicate with normal persons. Sign language is great method for hearing impaired to communicate, but unless everyone around is fluent in the visual language, it is not much of help. So, using the motion sensing technology of Leap Motion Controller, we can easily detect the different signs made by hands. And afterwards, we can translate this detected sign/gesture into speech or text. 
We also extended this project to control the 5 DOF(Degree of Freedom) Robotic Arm using Leap Motion sensor.
You can watch the video of both the projects in my YouTube channel.
https://www.youtube.com/channel/UCGpGRR1mEtjkwiD4PfDH6sw
To more know about these projects, you can drop me an email at utsav.p.shah@gmail.com
Or connect with me on LinkedIn at 
https://www.linkedin.com/in/utsavshah01
